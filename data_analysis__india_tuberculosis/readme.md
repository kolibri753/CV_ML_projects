# TB Data Analysis and Modeling

# Регуляризація: Lasso та Ridge

Регуляризація — техніка, що додає до функції втрат штраф за складність моделі, щоб запобігти перенавчанню (overfitting). Дві найпопулярніші лінійні регуляризовані моделі — Ridge (L2) та Lasso (L1).

---

## Ridge Regression (L2-​штраф)

- **Вплив на модель**  
  - Зменшує абсолютні значення усіх $\beta_j$, але не зануляє їх.  
  - Уникнення мультиколінеарності: коли ознаки корельовані, Ridge розподіляє вагу між ними.

- **Коли використовувати**  
  - Якщо є багато корельованих ознак.  
  - Якщо хочемо зберегти всі ознаки, але контролювати їхню величину.

---

## Lasso Regression (L1-​штраф)

- **Вплив на модель**  
  - Штраф за абсолютні значення коефіцієнтів призводить до *занулення* менш важливих $\beta_j$.  
  - Виконує **вбудований відбір ознак** (feature selection).

- **Коли використовувати**  
  - Коли потрібно отримати стиснуту, інтерпретовану модель.  
  - Якщо очікується, що лише невелика підмножина ознак є релевантною.

---

## Порівняння Lasso vs Ridge

| Параметр             | Ridge (L2)                    | Lasso (L1)                    |
|----------------------|-------------------------------|-------------------------------|
| Штраф               | $\sum \beta_j^2$             | $\sum |\beta_j|$             |
| Ефект на $\beta$     | Зменшує, але не занулює       | Може занулювати               |
| Відбір ознак         | Ні                            | Так                           |
| Стійкість до шуму    | Вища                          | Може бути чутливішою         |
| Рекомендоване α      | невелике (0.1–10)             | може бути більше (1–100)      |

---

## Практичне дослідження на датасеті

1. **Підготовка**  
   - Масштабування ознак (`StandardScaler`).  
   - Розбиття на тренувальний і тестовий набори (`train_test_split`).

2. **Пошук гіперпараметра α**  
   - Використати `GridSearchCV` або `RandomizedSearchCV` з переліком значень $\alpha$ (наприклад, [0.001, 0.01, 0.1, 1, 10, 100]).  
   - Вибрати метрику (R² або MSE) для оцінки.

3. **Навчання та оцінка**  
   ```python
   from sklearn.linear_model import Ridge, Lasso
   from sklearn.model_selection import GridSearchCV

   param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}
   ridge_cv = GridSearchCV(Ridge(), param_grid, cv=5, scoring='r2').fit(X_train, y_train)
   lasso_cv = GridSearchCV(Lasso(max_iter=10_000), param_grid, cv=5, scoring='r2').fit(X_train, y_train)

   print("Best Ridge α:", ridge_cv.best_params_, "R²:", ridge_cv.best_score_)
   print("Best Lasso α:", lasso_cv.best_params_, "R²:", lasso_cv.best_score_)

---

## 1. Data Preprocessing
- **Loading**: imported `filled_final_data.xlsx`, inspected with `head()` and `info()`.  
- **Missing values**: checked `isnull().sum()` → жодних пропусків.  
- **Categorical vs numeric**: єдина категоріальна змінна — `City`; переконались, що для всіх міст є повні річні дані.  
- **Feature removal**: видалили `City` та `Year` (не прямі предиктори, могли створювати шум).  
- **Scaling**: застосували `StandardScaler` до всіх числових стовпців (mean=0, std=1).  
- **Descriptive stats**: через `describe()` виявили велику кількість нулів, екстремальні максимуми та асиметрію розподілів.

---

## 2. Exploratory Analysis
- **Active TB cases**: μ≈3295, σ≈10180, max=73 772 → нерівномірний процес діагностики.  
- **TB among tested**: median≈9702 vs max≈2 046 453 → неоднорідність доступу до діагностики.  
- **MDR/RR-TB**: μ≈3007, σ≈9298 → відмінності в тестуванні мультирезистентного ТБ.  
- **Pediatric TB**: μ≈6576, σ≈20242 → великі регіональні/часові коливання.  
- **Gender cases**: сплески вказують на локальні епідемії.  
- **TB–HIV coinfection**: низька медіана vs висока макс. → недостатнє тестування.  
- **Treatment outcomes**: смертність до 5.388 % → нерівномірна якість лікування.  
- **Risk factors** (тютюн/алкоголь): екстремальні максимуми підкреслюють дисбаланс.  
- **Infrastructure**: 0–162 центрів MDR-TB → нерівномірність доступу.  
- **TB & COVID-19**: μ≈239, max≈4996 → значні регіональні перетини епідемій.

---

## 3. Correlation Heatmap
- Побудували матрицю кореляцій (–1…1).  
- Виокремили пари зі сильною кореляцією (наприклад, чоловічі vs жіночі випадки ТБ).  
- Зауважили низьку кореляцію `City_encoded` → мінімальний регіональний ефект.  
- Використали для виявлення мультиколінеарності та відбору ознак.

---

## 4. Target Distribution
- Гістограма `TB case notification total` показала яскраво виражену праву асиметрію та викиди (>500).  
- Рекомендації: перевірити аномалії, розглянути логарифмічне перетворення для стабілізації розподілу.

---

## 5. Pairwise Scatter Plots
- Приклад: `TB Cases Notified Female` vs `total`.  
- Більшість точок низькі, кілька викидів → слабка лінійна залежність.  
- Показує, що частка жіночих випадків не завжди пропорційна загальній кількості.

---

## 6. Linear Regression
- **Split**: 80 % train / 20 % test.  
- **Train**: `LinearRegression` → Train R²≈0.31, Test R²≈–0.57 → погана генералізація.  
- **5-fold CV**: середній R²≈–12 → дуже нестабільна модель.

---

## 7. Regularisation
- **Методи**: Lasso (L1) та Ridge (L2) з α=0.1.  
- **Tuning**: GridSearchCV  
  - Lasso → оптимальне α=1 (більшість коефіцієнтів = 0).  
  - Ridge → оптимальне α=100 (усі коефіцієнти зменшені, але не занулені).  
- **Результати**: Ridge трохи перевершує Lasso, але обидві моделі поступаються нелінійним алгоритмам.

---

## 8. Feature Importance
- Порівняли коефіцієнти трьох моделей:  
  - **Linear**: велика варіативність → ризик перенавчання.  
  - **Lasso**: вибірковість → лише найважливіші ознаки.  
  - **Ridge**: збалансовані ваги → стабільніший вплив.

---

## 9. Model Comparison
- Визначили функцію `evaluate_model()` для RMSE & R² на train/test.  
- Порівняли Decision Tree, KNN, SVR, Random Forest:  
  - **Decision Tree**: ідеальна підгонка train, найкраще на test, але очевидний overfit.  
  - **KNN**: помірна точність.  
  - **SVR**: негативне тестове R² → гірше за константу.  
  - **Random Forest**: найкращий баланс точності та стійкості до overfit.

---

## Conclusions
- Вихідні дані мають сильну варіативність, асиметрію та викиди.  
- Лінійні моделі погано справляються, регуляризація покращує стабільність, але не достатньо.  
- Нелінійні методи (особливо Random Forest) краще обробляють складні залежності та аномалії.  
- Рекомендації: додаткова обробка викидів, лог-перетворення, розширена інженерія ознак та дослідження бустингових алгоритмів.
