# Titanic Ensemble Learning Report

## 1. Вступ

В якості основи обрано датасет **Titanic – Machine Learning from Disaster**. Мета дослідження — не лише підвищити точність класифікації, а й систематично дослідити ключові етапи pipeline: від інженерії ознак до побудови та складання ансамблевих моделей.

## 2. Мотивація та концептуальні підходи

- **Доменно-орієнтоване інженерування ознак**  
  Використання титулів та соціально-економічних індикаторів (Pclass, Cabin) для збагачення інформації про пасажирів.  
- **Баланс упередження та дисперсії**  
  Поєднання методів bagging (Random Forest, Extra Trees) і boosting (AdaBoost, Gradient Boosting) дозволяє скоротити variance та bias одночасно.  
- **Stacking як метод корекції**  
  Застосування метамоделі (логістичної регресії) до прогнозів базових алгоритмів для виявлення залишкових патернів.

## 3. Архітектура процесу

### 3.1 Підготовка даних

1. **Завантаження**  
   Об’єднання `train.csv` і `test.csv` для єдиного підходу до інженерії ознак.  
2. **Аналіз структури**  
   Використання `info()`, `describe()`, `isnull().sum()` для виявлення типів даних і пропусків.  
3. **Інженерія ознак**  
   - **Title Extraction**: виділення титулів з поля `Name`, групування рідкісних категорій у `Rare`.  
   - **Age Imputation**: заповнення пропусків медіанами віку для кожної комбінації `(Title, Pclass)`.  
   - **Fare Transformation**: логарифмічне перетворення для зменшення skew.  
   - **Cabin і Ticket Prefix**: виділення колеса каюти та префіксу квитка як категоріальних індикаторів.  
4. **Кодування та масштабування**  
   - One-hot encoding для `Embarked`, `Cabin`, `TicketPrefix`.  
   - Label encoding для `Sex`, `Title`.  
   - StandardScaler для числових змінних.

### 3.2 Побудова моделей

1. **Базові алгоритми**  
   - **Bagging**: Random Forest, Extra Trees  
   - **Boosting**: AdaBoost, Gradient Boosting  
   - **Support Vector Classifier**  
2. **Ансамбль Stack­ing**  
   - Комбінація прогнозів базових моделей  
   - Мета-модель: Logistic Regression  
   - Крос-валідація (k-fold) для надійності оцінки

## 4. Оцінка моделей

- Метрики: Accuracy, Precision, Recall, F1, AUC ROC  
- Діаграми: confusion matrix, ROC-криві  
- Порівняння результатів  
  - Extra Trees і Random Forest демонструють високу стабільність.  
  - SVC показує найвищу точність на тестовій вибірці серед одиночних моделей.  
  - Stacking дає найбільш збалансований результат на тесті.

## 5. Головні висновки

1. **Якість заповнення Age за Title/Pclass** підвищує узагальнюваність моделей.  
2. **Ансамблеві методи** суттєво перевершують поодинокі алгоритми за стабільністю та стійкістю до шуму.  
3. **Stacking** ефективно ловить залишкові патерни, які не враховані bagging чи boosting.  
4. **Feature importance** в ансамблях підтверджує значущість соціально-економічних індикаторів та титулів.

---

# Ансамблеве навчання: теоретичний огляд

## 1. Вступ

Ансамблеве навчання (Ensemble Learning) — підхід, що поєднує кілька простих моделей у одну складну систему для підвищення точності та стійкості прогнозів. Ідея полягає в тому, що різні алгоритми роблять різні помилки, і їх об’єднання зменшує сумарну похибку.

---

## 2. Ключові поняття

- **Variance (дисперсія)**  
  Чутливість моделі до коливань даних. Висока дисперсія ≈ переобучення.

- **Bias (упередження)**  
  Систематична похибка, що виникає, коли модель надто спрощена.

- **Bias–Variance Tradeoff**  
  Баланс між упередженням і дисперсією:
  - Bagging знижує дисперсію.
  - Boosting знижує упередження.
  - Stacking поєднує та мінімізує обидва.

- **Diversity (різноманітність)**  
  Ансамбль ефективний тоді, коли базові моделі роблять незалежні помилки.

---

## 3. Основні методи

### 3.1 Bagging (Bootstrap Aggregating)

1. **Алгоритм**  
   - Для і=1…K:  
     - Створити bootstrap-вибірку (розмір N) з початкового датасету.  
     - Навчити базовий класифікатор hᵢ на цій підмножині.  
   - Для нових даних X отримати прогнози h₁(X), …, hₖ(X) та об’єднати:
     - Класифікація: прогноз = majority_vote(h₁(X),…,hₖ(X))  
     - Регресія: прогноз = average(h₁(X),…,hₖ(X))

2. **Перевага**  
   Зменшує дисперсію, стійкий до переобучення.

### 3.2 Boosting

1. **AdaBoost**  
   - Присвоює ваги прикладам, наголошуючи на тих, що були неправильно класифіковані.  
   - На кожному кроці t:  
     - Навчити слабкий класифікатор hₜ на зважених даних.  
     - Обчислити помилку εₜ = sum(weights_of_misclassified) / sum(all_weights).  
     - Вага моделі αₜ = 0.5 * ln((1−εₜ)/εₜ).  
     - Оновити ваги прикладів:  
       ```text
       new_weight_i = old_weight_i * exp(−αₜ * y_i * hₜ(x_i))
       ```
     - Нормалізувати всі ваги.

   - Фінальний прогноз:
     ```text
     H(x) = sign( sum_{t=1..T} αₜ * hₜ(x) )
     ```

2. **Gradient Boosting**  
   - Будує кожну нову модель для прогнозування залишків (градієнтів) попередньої, мінімізуючи функцію втрат по градієнту.

3. **Перевага**  
   Знижує упередження, дозволяє будувати високо точні моделі.

### 3.3 Stacking (Stacked Generalization)

1. **Алгоритм**  
   - Навчити N базових моделей на повному наборі даних.  
   - Зібрати їхні прогнози (out-of-fold) як нові ознаки.  
   - Навчити мета-модель на цих прогнозах, використовуючи крос-валідацію, щоб уникнути витоку інформації.

2. **Перевага**  
   Комбінує сильні сторони різних алгоритмів і коригує залишкові помилки.

---

## 4. Декомпозиція помилки

Загальна очікувана помилка моделі може бути розкладена як:
```text
Total_Error ≈ Bias^2 + Variance + Irreducible_Error
````

Ансамблі мінімізують перші дві складові.

---

## 5. Умови ефективності ансамблю

1. **Сила (strength)**
   Кожна базова модель має працювати краще випадкового вгадування.

2. **Різноманітність (diversity)**
   Помилки моделей повинні бути слабо корельовані між собою.

---

## 6. Висновки

* **Bagging** підходить для моделей з високою дисперсією (наприклад, дерева).
* **Boosting** корисний при високому упередженні лінійних моделей.
* **Stacking** забезпечує додатковий рівень корекції, об’єднуючи прогнози різнорідних алгоритмів.
* Поєднання цих методів дає синергетичний ефект і значне підвищення якості прогнозів.
